# Description
This is containerised dev environment made for playing around wiht Spark 3.2 and Python 3.7.

# How to use
1. Open in VS Code using the `Remote-Containers` extension
2. Run the notebooks in `notebooks/` to see examples of using PySpark

# Resources
Based on these resources:
* https://www.kdnuggets.com/2020/07/apache-spark-cluster-docker.html
* https://computingforgeeks.com/how-to-install-apache-spark-on-ubuntu-debian/
* https://spark.apache.org/docs/latest/api/python/getting_started/install.html
* https://www.youtube.com/watch?v=_C8kWso4ne4
